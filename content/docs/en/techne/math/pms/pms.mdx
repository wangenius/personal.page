---
title: 概率论
sidebar_position: 1
slug: 概率论
---

> 概率论和数理统计研究的对象是随机对象，不总出现相同结果的现象。

> 一共有两种路线：一是已知总体的分布函数，求概率。二是通过随机抽样得到的样本，对总体的未知参数进行估计。

### 样本试验

1.  样本点$\omega$：观测结果的最小单位。 
2.  样本空间$\Omega$：即结果集，其中每一个基本结果为样本点（基本事件）。 
3.  随机试验$E$：对样本空间的一次观测，条件相同，结果有限未知。 
> 古典模型：

> 1. 乘法原理和加法原理；
{/* > 2. $P_n^r=\dfrac{n!}{(n-r)!}\qquad C_n^r=\dfrac{P_n^r}{r!}$ */}
> 3. 重复排列:$n^r$
> 4. 重复组合$C_{n+r-1}^r$
> 5. 伯努利试验：$C_n^kp^k(1-p)^{n-k}$

 

4.  随机事件$ABC$：随机事件是由若干样本点构成的集合。必然事件为全集，不可能事件为空集。 
> 掷骰子中，A=\{出现奇数点\}是一个事件。即$A=\{1,3,5\}$，而$1,3,5$为样本点。

 

   1. 包含，相等，相容，互斥，对立，并，差，交
   2. 分配律：内并外交 = 内交并内交，内交外并 = 内并交内并，内差交 = 内交差
   3. 对偶律：长杠并短杠，开口换方向

**概率**：随机事件$A$可能性大小的度量，满足非负性、规范性、可列可加性（任意可列个两两互斥事件的概率和=和事件的概率）。

{/* 1.  $0<PA<1;P(\varnothing)=0,P\left(\Omega\right)=1$  */}
> 概率等于0不等于不可能事件，概率等于1，不等于必然事件

 

2.  $P\overline A=1-PA$ 
3.  $B\subset A\implies P\left(A-B\right)=PA-PB$ 
4.  $P(A-B)=PA-PAB=PA\overline B$ 
5.  $P(A+B)=P\left(A\cup B\right)=PA+PB-PAB$ 
6.  $P(A\cup B\cup C)=PA+PB+PC-PAB-PAC-PBC+PABC$ 
7.  $A\perp B\implies PAB=PA\cdot PB$ 
8.  条件概率公式：$P(B|A)=\dfrac{PAB}{PA}$ 
> 条件发生，样本空间坍缩;；$PA=PA\cdot P\Omega$

 

9.  全概率公式：$B=\bigcup A_{i}B\implies PB=\sum P\left(A_{i}\right)\cdot P\left(B\left|A_{i}\right.\right)$ 
> $A$是样本空间的分隔。对于任意的事件$B$，其概率=在每个$A$空间下的$B$的概率和

 

10.  逆概率公式：条件概率公式的分子用乘法公式，分母用全概率公式展开 

{/* $P(A_{j}\left|\right.B)=\dfrac{PA_{j}\cdot P\left(B\left|A_{j}\right.\right)}{\sum_{i=1}^{n}PA_{i}P\left(B\left|A_{i}\right.\right)}\left(j=1,2,\cdots,n\right)$ */}

11.  

### 数理统计

> 通过对部分的调查，来估算分布参数。

1.  总体：所有个体的数量指标值，总体的分布就是随机变量$X$的分布。抛开实际背景，总体就是一堆数，这堆数中有大有小，有得出现机会多，有的出现机会少，因此用一个概率分布去描述和归纳总体是恰当的，从这个意义上看，总体就是一个分布。 
2.  样本：总体中随机抽取$n$个个体，记录指标$\{X_1,\cdots ,X_n\}$，则称为总体的一个样本，$n$称为样本容量。样本中的个体称为样品。随机变量$\{X_1,\cdots ,X_n\}$的具体数值$\{x_1,\cdots ,x_n\}$成为观测值。 
> 可以看出，样本个体是独立同分布，一个样本就是独立同分布的多维随机变量序列。样本的分布便和多维随机变量序列的分布是相同的。

 

3.  统计量：我们构造适当的样本函数对样本进行分析，这个样本函数就叫统计量。对样本的统计方法，在对样本观测后，可以生成一个观测值组。对观测值组使用统计量的函数进行分析，得到计算出的两统计量不依赖于任何未知参数，作为随机样本的函数，统计量也是随机变量$g(X_1,X_2,\cdots,X_n)$。统计量的分布叫作抽样分布，不同抽样（不同样本所带来的统计量是不同的，但是相关）。 
{/* 4.  估计量：由样本构造一个适当的统计量，$\hat{\theta}(X_1,X_2,\cdots,X_n)$作为参数的估计。  */}
{/* > 1. 无偏性：$E\hat{\theta}=\theta$ */}
{/* > 2. 有效性：$D\hat{\theta_1}< D\hat{\theta_2}$，$\hat{\theta_1}$比$\hat{\theta_2}$有效 */}
{/* > 3. 一致相合性：切比雪夫不等式：$\lim_{n\to+\infty}P\{|\hat{\theta}-\theta|< \varepsilon\}=1$ */}

 

> 感性的理解：总体是一个类，有一定的属性，这个“一定”指的是有限个明确的但无法确定的属性。这种属性在对它的每一次“初始化”（观测行为）而不同，因此是具有随机性概率性的。我们可以把分配的空间叫做随机变量，每对总体进行一次的观测行为，得到一个样品。多次的观测样本。

```typescript
//总体
class Gross{
	number x;
	constructor(){
	//每次new一个类时，就会随机生成x的值；
	//random算法的确定，确定了Gross.x总体的期望值和方差，这是研究对象的本质属性
	this.x = random(1,2,3,4,5,6,7);
	}
}

//实例化就是一种观测行为
//X就是样本,每一个元素个体叫做样品(每一个样品相当于一个随机变量)，观测值又叫样品值,
const X : number = [];
X[0] = new Gross().x;
X[1] = new Gross().x;

//一种统计量
const statistic_1: number = (X : number[])  => handle_1(X);
//第二种统计量
const statistic_2: number = (X : number[])  => handle_2(X);
```

常用统计量：

1.  样本均值(一阶原点矩)：$\overline{X}=\dfrac{1}{n}\sum_{i=1}^{n}X_i$ 
2.  样本方差：$S^2=\dfrac{1}{n-1}\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^2$ 
> 关于样本均值的平均偏差平方和。（二阶中心矩）

 

3.  样本$k$阶原点矩==：$A_{k}=\dfrac{1}{n}\sum_{i=1}^{n}X_{i}^{k}$ 
4.  样本$k$阶中心距：$B_{k}=\dfrac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{k}$ 
5.  顺序统计量：从小到大的排列。 

样品的期望等于总体的期望，样品的方差=总体的方差，样本方差的期望=总体的方差，样本均值的期望=总体的期望。样本均值的方差=$\dfrac1n$总体的方差。

### 随机变量

> 随机变量$X$：样本点的数内映射，分为连续型随机变量和离散型随机变量。
>  
> 分布函数$F$：事件$\{\omega|X(\omega)< x,\omega\in\Omega\}$的概率函数。
>  
> 概率密度/概率分布$f(x)$：样本点的概率函数。

一维随机变量：

1.  分布函数`CDF`：$X\sim F(x)=P\{X\le x\}(x\in R)$
单调不减右连续，无穷等于0和1:$P\left\lbrace X< a\right\rbrace=F\left(a-0\right),P\left\lbrace X\le a\right\rbrace=F\left(a\right),P\left\lbrace X=a=F\left(a\right)-F\left(a-0\right)\right.$ 
2.  离散型分布律：$x\sim\begin{bmatrix}x_1 & x_2 & x_3 & \cdots\\ p_1 & p_2 & p_3 & \cdots\end{bmatrix}$ 
3.  连续性概率密度：$x\sim f(x);$
{/* $F(x)=\int_{-\infin}^x f(t)\mathrm{d}t,x\in R\qquad f(x)>0$ */}
{/* $P\left\lbrace{a<x<b}\right\rbrace=P\left\lbrace a\le x\le b\right\rbrace=\int_{a}^{b}f\left(x\right)\mathrm{d}x=F\left(b\right)-F\left(a\right)$  */}

多维随机变量：同一个样本空间$\Omega$上的$n$维随机变量

1.  联合分布函数:性质：单调不减右连续，极限等于0和1 
2.  边缘分布函数: 
{/* 3.  条件分布函数:$\begin{cases}F_{X|Y}\left(x|y\right)=\int_{-\infty}^{x}\dfrac{f\left(x,y\right)}{f_{Y}\left(y\right)}\mathrm{d}x\\ F_{Y|X}\left(x|y\right)=\int_{-\infty}^{y}\dfrac{f\left(x,y\right)}{f_{X}\left(x\right)}\mathrm{d}y\end{cases}$  */}
{/* 4.  概率密度:$\dfrac{{\partial}^2F\left(x,y\right)}{{\partial x\partial y}}=f\left(x,y\right)$  */}
{/* 5.  边缘概率密度:$\begin{cases}f_{X}\left(x\right)=\int_{-\infty}^{+\infty}f\left(x,y\right)\mathrm{d}y\\ f_{Y}\left(y\right)=\int_{-\infty}^{+\infty}f\left(x,y\right)\mathrm{d}x\end{cases}$  */}
> 求谁谁划线，限内定积分，先交写下限，后交写上限

 

{/* 6.  条件概率密度:$\begin{cases}f_{X|Y}\left(x|y\right)=\dfrac{f\left(x,y\right)}{f_{Y}\left(y\right)}\left(f_{Y}\left(y\right)>0\right)\\ f_{Y|X}\left(x|y\right)=\dfrac{f\left(x,y\right)}{f_{X}\left(x\right)}\left(f_{X}\left(x\right)>0\right)\end{cases}$  */}
> 条件=联合/边缘

 

随机变量分布：

{/* 1.  $B(1,p)=\begin{pmatrix}1 & 0\\ p & 1-p\end{pmatrix}\implies P\left\lbrace X=1\right\rbrace=p;P\left\lbrace X=0\right\rbrace=1-p$ */}
{/* $EX=p;DX=p(1-p)$  */}
{/* 2.  $B(n,p)\implies P\left\lbrace X=k\right\rbrace=C_{n}^{k}p^{k}\left(1-p\right)^{n-k}$ */}
{/* $EX=np;DX=np(1-p)$  */}
{/* 3.  $P(\lambda)\implies P\left\lbrace X=k\right\rbrace=\dfrac{\lambda^{k}}{k!}e^{-\lambda}(\lambda>0)$ */}
{/* $EX=\lambda;DX=\lambda$  */}
{/* 4.  $E(\lambda)=f(x)=\begin{cases}\lambda e^{-\lambda x},x>0\\ 0,x\le0\end{cases}\implies F(x)=\begin{cases}1-e^{-\lambda x},x\ge0\\ 0,x< 0\end{cases}$ */}
{/* $EX=\dfrac{1}{\lambda};DX=\dfrac{1}{\lambda^2}$  */}
{/* 5.  $N(\mu,\sigma^2)=f(x)=\dfrac{1}{\sqrt{2\pi}\sigma}e^{-\dfrac12(\dfrac{x-\mu}{\sigma})^2}\implies \Phi\left(x\right)=\dfrac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\dfrac{t^2}{2}}\mathrm{dt}$ */}
{/* $EX=\mu;DX=\sigma^2$  */}
{/* 6.  $U(a,b)=\begin{cases}\dfrac{1}{b-a},a< x< b\\ 0,rest\end{cases}\implies F(x)=\begin{cases}0,x< a\\ \dfrac{x-a}{b-a},a\le x< b\\ 1,x\ge b\end{cases}$ */}
{/* $EX=\dfrac{a+b}{2};DX=\dfrac{(b-a)^2}{12}$  */}
{/* 7.  $G(p)\Longrightarrow p\{X=k\}=(1-p)^{k-1}p$ */}
{/* $EX=\dfrac1p;EX=\dfrac{1-p}{p^2}$  */}
{/* 8.  $H(n,N,M)\Longrightarrow P\{X=k\}=\dfrac{C_{M}^{k}C_{N-M}^{n-k}}{C_{N}^{n}}$ */}
{/* $EX=n\dfrac MN$  */}
{/* 9.  二维均匀分布：$f(x)=\begin{cases}\dfrac{1}{S_{D}},\left(x,y\right)\in D\\ 0,rest\end{cases}$  */}
{/* 10.  二维正态分布$\left(X,Y\right)\sim N\left(\mu_1,\mu_2;\sigma_1^2,\sigma_2^2;\rho\right)$：$f\left(x\right)=\dfrac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\exp\left\lbrace-\dfrac{1}{2\left(1-\rho^2\right)}\left\lbrack\left(\dfrac{x-\mu_1}{\sigma_1}\right)^2-2\rho\left(\dfrac{x-\mu_1}{\sigma_1}\right)\left(\dfrac{x-\mu_2}{\sigma_2}\right)+\left(\dfrac{y-\mu_2}{\sigma_2}\right)^2\right\rbrack\right\rbrace$  */}

{/* > **泊松定理**：在$n$重伯努利试验中，事件$A$在一次试验中发生的概率为$p_n$（与试验次数$n$有关），如果当$n$趋于无穷大时，$np_n\to\lambda$,则$\lim_{n\to\infin}C^k_np^k_n(1-p_n)^{n-k}=\dfrac{\lambda^k}{k!}e^{-\lambda}$ */}
>  
> 二项分布$B(n,p)$中，很大，$p$很小，乘积$\lambda$大小适中时，可以用**泊松分布做近似**。
{/* $C^k_np^k_n(1-p_n)^{n-k}=\dfrac{(np)^k}{k!}e^{-np}$ */}
{/* >  
> 指数分布具有无记忆性：$P\left\lbrace X>t\right\rbrace=1-F\left(t\right)=e^{-\lambda t}$ */}

### 变量函数

一维：

{/* 1离散型：$\left.\begin{array}{l}Y=g(X)\\ X\sim p_{i}=P\left\lbrace X=x_{i}\right\rbrace\end{array}\right\}\implies P\left\lbrace Y=g\left(x_{i}\right)\right\rbrace=p_{i}\;\iff\;Y\sim\begin{bmatrix}g\left(x_1\right)&g(x_2)&\cdots\\ p_1&p_2&\cdots\end{bmatrix}$ */}

{/* 连续型：$\left.\begin{array}{l}Y=g(X)\\ X\sim f\left(x\right)\end{array}\right\}\implies F_{Y}(y)=P\left\lbrace Y\le y\right\rbrace=P\left\lbrace g\left(X\right)\le y\right\rbrace=\int_{g\left(x\right)\le y}f_{X}\left(x\right)\mathrm{d}x$ */}

多维：

1.  $U=g(X,Y)$ 
{/* 2.  $Z=X+Y\Longrightarrow f\left(z\right)=\int_{-\infty}^{+\infty}f\left(x,z-x\right)\mathrm{d}x=\int_{-\infty}^{+\infty}f\left(z-y,y\right)\mathrm{d}y$ */}
{/* 当$X\perp Y\Longrightarrow f_{z}\left(z\right)=\int_{-\infty}^{+\infty}f_{X}\left(x\right)f_{Y}\left(z-x\right)\mathrm{d}x=\int_{-\infty}^{+\infty}f_{X}\left(z-y\right)f_{Y}\left(y\right)\mathrm{d}y$  */}
{/* 3.  $Z=X-Y\Longrightarrow f\left(z\right)=\int_{-\infty}^{+\infty}f\left(x,x-z\right)\mathrm{d}x=\int_{-\infty}^{+\infty}f\left(y+z,y\right)\mathrm{d}y\overset{X\perp Y}{\implies}\int_{-\infty}^{+\infty}f_{X}\left(y+z\right)f_{Y}\left(y\right)\mathrm{d}y$  */}
{/* 4.  $Z=XY\Longrightarrow f_{Z}\left(z\right)=\int_{-\infty}^{+\infty}\dfrac{1}{\left|x\right|}f\left(x,\dfrac{z}{x}\right)\mathrm{d}x=\int_{-\infty}^{+\infty}\dfrac{1}{\left|y\right|}f\left(\dfrac{z}{y},y\right)\mathrm{d}y\overset{X\perp Y}{\implies}\int_{-\infty}^{+\infty}\dfrac{1}{\left|x\right|}f_{X}\left(x\right)f_{Y}\left(\dfrac{z}{x}\right)\mathrm{d}x=\int_{-\infty}^{+\infty}\dfrac{1}{\left|y\right|}f_{X}\left(\dfrac{z}{y}\right)f_{Y}\left(y\right)\mathrm{d}y$  */}
{/* 5.  $Z=\dfrac{X}{Y}\implies f_{Z}\left(z\right)=\int_{-\infty}^{+\infty}\left|y\right|f\left(yz,y\right)\mathrm{d}y\overset{X\perp Y}{\implies}\int_{-\infty}^{+\infty}\left|y\right|f_{X}\left(yz\right)f_{Y}\left(y\right)\mathrm{d}y$  */}
{/* 6.  $Z=\max\left\lbrace X,Y\right\rbrace\implies F_{\max}\left(z\right)=P\left\lbrace\max\left\lbrace X,Y\right\rbrace\le z\right\rbrace=P\left\lbrace X\le z,Y\le z\right\rbrace=F\left(z,z\right)$ */}
{/* $F_{\max}\left(z\right)=F_{X}\left(z\right)\cdot F_{Y}\left(z\right)$  */}
{/* 7.  $Z=\min\left\lbrace X,Y\right\rbrace\implies F_{\min}\left(z\right)=P\left\lbrace\left\lbrace X\le z\right\rbrace\cup\left\lbrace Y\le z\right\rbrace\right\rbrace=F_{X}\left(z\right)+F_{Y}\left(z\right)-F\left(z,z\right)\overset{X\perp Y}{\implies}\overset{}{1-\left\lbrack1-F_{X}\left(z\right)\right\rbrack\left\lbrack1-F_{Y}\left(z\right)\right\rbrack}$  */}

{/* > $X_{(n)}=\max\{X_1,\cdots,X_n\}\implies F_{\max}\left(x\right)=[F\left(x\right)]^{n}$ */}
{/* >  
> $X_{(1)}=\min\{X_1,\cdots,X_{n}\}\implies F_{\min}\left(x\right)=1-\left\lbrack1-F\left(x\right)\right\rbrack^{n}$ */}

### 数字特征

> 期望====：描述随机变量平均取值状况特征的指标，加权平均,刻画随机变量平均取值状况特征的指标，刻画随机变量的一切可能值的集中位置。**有**==**概率密度****不一定****有期望** **，级数或连续型积分需要****绝对收敛**== **。**

{/* $EX=\sum x_ip_i;EX=\sum g(x_i)p_i$ */}

{/* $EX=\int_{-\infty}^{+\infty}xf\left(x\right)\mathrm{d}x;EX=\int_{-\infty}^{+\infty}g\left(x\right)f\left(x\right)\mathrm{d}x$ */}

{/* $E(aX+bY+c)=aEX+bEY+c$ */}

{/* $X\perp Y\implies EXY=EX\cdot EY$ */}

{/* $X\perp Y\implies E[g_1(X)\cdot g_2(Y)]=E{g_1}(X)\cdot Eg_2(Y)$ */}

{/* > 方差$DX$==：偏差平方的期望值。方差一定且大于0时，观测值距离期望越远（$\epsilon$越大），概率越小。当方差越小时，约束越强，观测值在远端的可能性越小。当方差越大时，约束性弱，观测值在远端的可能性减小速度放缓。 */}

{/* $DX=E\left\lbrack\left(X-EX\right)^2\right\rbrack=EX^2-E^2X$ */}

{/* 1. $DX\ge0,EX^2=DX+E^2X\ge E^2X$ */}
{/* 2. $D(aX+b)=a^2DX$ */}
{/* 3. $D\left(aX\pm bY\right)=a^2DX+b^2DY\pm2abCov\left(X,Y\right)$ */}
{/* 4. $D\left\lbrack\sum g_{i}\left(X_{i}\right)\right\rbrack=\sum D\left\lbrack g_{i}\left(X_{i}\right)\right\rbrack$ */}

{/* > 标准差$\sigma  X$==： */}

{/* 1. $\sigma X=\sqrt{DX}$ */}
{/* 2. $X^*=\dfrac{X-EX}{\sqrt{DX}}$是标准化随机变量，此时$EX^*=0,DX^*=1$ */}

多维随机变量的数字特征:

{/*   1.  $E(g(X,Y))=\sum\sum g(x_i,y_i)p_{ij}=\int_R\int_Rg(x,y)f(x,y)dxdy$(绝对收敛)  */}
{/* > $g(X,Y)$是X，Y函数。$f(x,y)$是概率密度 */}

 

{/* 2.  $Cov(X)=E((X-EX)(Y-EY))=EXY-EXEY$  */}
{/* > 协方差描述随机变量之间偏差的关联程度。 */}

 

{/* 3.  $\rho_{XY}=\dfrac{Cov(X,Y)}{\sqrt{DX}\sqrt{DY}}$  */}
{/* > 相关系数用来描述随机变量之间的线性相依性。如果=0,则$xy$不相关（线性相关），如果不等于0,则相关。线型相依性，不相关不代表XY之间不存在相依关系， 它们之间可能存在非线性关系。 */}

 

{/* 4.  $Cov(X,Y)=Cov(Y,X),\rho_{XY}=\rho_{YX}$，$Cov(X,X)=DX$，$\rho_X=1$  */}
{/* 5.  $Cov(X,c)=0,Cov(aX+b,Y)=aCov(X,Y)$  */}
{/* 6.  $Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)$  */}
{/* 7.  $|\rho_{XY}|\le1$  */}
{/* 8.  $Y=aX+b,\rho_{XY}=\left\{\begin{array}{}1&a>0;\\ -1&a<0;\end{array}\right.$  */}

{/* > **切比雪夫不等式**：$\forall\varepsilon>0,P\left\lbrace\left|X-EX\right|\ge\varepsilon\right\rbrace\le\dfrac{DX}{\varepsilon^2}=\left(\dfrac{\sigma X}{\varepsilon}\right)^2$：表明方程是刻画随机变量与其期望值偏离程度的量，是描述随机变量X分散程度特征的指标。说明偏差大于等于某个值的概率是小的。偏差大于等于某个值的概率小于等于方差比上该值的平方。 */}

### 三大分布

{/* 卡方分布：$X\sim\chi^2(n)=\sum_{i=1}^nx_i^2$随机变量$\left\lbrace X_{i}\right\rbrace$相互独立同标准正态分布，$X$服从自由度为$n$的卡方分布。 */}

{/* 上$\alpha$分位点：$P\left\lbrace\chi^2>\chi_{\alpha}^2\left(n\right)\right\rbrace=\int_{\chi_{\alpha}^2\left(n\right)}^{+\infty}f\left(x\right)\mathrm{d}x=\alpha$ */}

{/* $X_1\sim\chi^2(n),X_2\sim\chi^2(m)\implies X_1+X_2\sim\chi^2(n+m)$ */}

{/* $EX=n,DX=2n$ */}

{/* 分布：$X\sim N(0,1),Y\sim \chi^2(n)$,$t=\dfrac{X}{\sqrt{Y/n}}$服从自由度为$n$的$t$分布。$t\sim t(n)$ */}

$Et=0$

{/* $-t_\alpha(n)=t_{1-\alpha}(n)$ */}

$F$分布==：$X\sim\chi^2(n_1),Y\sim\chi^2(n_2)$，$XY$相互独立：$F=\sim F(n_1,n_2)=\dfrac{X/n_1}{Y/n_2}$

{/* $F_{1-\alpha}(n_1,n_2)=\dfrac{1}{F_\alpha(n_2,n_1)}$ */}
{/* 
> 正态总体条件下的常用结论：
>  
> 1. 标准正态化：$\overline{X}\sim N(\mu,\dfrac{\sigma^2}{n})\implies \dfrac{\overline{X}-\mu}{\dfrac{\sigma}{\sqrt{n}}}=\dfrac{\sqrt{n}(\overline{X}-\mu)}{\sigma}\sim N(0,1)$
> 2. $\dfrac{1}{\sigma^2}\sum^n(X_i-\mu)^2\sim \chi^2(n)$
> 3. $\dfrac{(n-1)S^2}{\sigma^2}=\sum_{i=1}^{n}\left(\dfrac{X_{i}-\bar{X}}{\sigma}\right)^2\sim\chi^2\left(n-1\right)$
> 4. $\bar{X}\perp S^2\implies\dfrac{\sqrt{n}\left(\bar{X}-\mu\right)}{S}\sim t\left(n-1\right)\implies\dfrac{n\left(\bar{X}-\mu\right)^2}{S^2}\sim F\left(1,n-1\right)$ */}

## 参数估计

> 总体$X$的分布函数中的形式已知，参数未知。根据样本和统计量估计参数.

点估计：
{/* 
1.  矩法估计:对于$n$个待估参数，取$n$个样本，构造$n$阶方程组。
先用$EX$求$\theta$,如果求不出，再用$E(X^2)$求。 
2.  最大似然估计法 
   1. 似然函数：$L\left(\theta\right)=P\left\lbrace X_1=x_{1,}X_2=x_2,\cdots,X_{n}=x_{n}\right\rbrace=\prod P\left\lbrace X_{i}=x_{i}\right\rbrace=\prod p\left(x_{i};\theta\right)$
   2. 似然函数取最大值时的$\theta$值。$\dfrac{dL}{d\theta}=0,\dfrac{d\ln L}{d\theta}=0$解出$\hat{\theta}$
   3. 最大似然估计量的不变性原则

区间估计：两个统计量确定一个置信区间。$\alpha$显著性水平。 */}

## 假设检验

> 根据样本观察数据和试验结果提供的信息去检验假设是否成立。采用代有概率性质的反证法，即小概率原理，概率很接近$0$的事件在一次试验或者观察中认为它不会发生。若发生了，拒絶原假设。规定一个显著性水平$\alpha$，当事件概率不大于$\alpha$时，认为它是小概率事件。

1. 统计假设：关于总体的每一种论断
2. 参数假设：总体分布函数形式已知，只有参数未知，只涉及参数的假设。
3. 简单假设：统计假设完全确定总体的分布
4. 基本假设：着重考察没有充分理由不能轻易否定的假设$H_0$
5. 对立假设：将基本假设否定的假设$H_1$
6. 显著性检验：对原假设进行否定或不否定的推断。
7. 否定域：拒絶原假设的全体样本点组成的集合$C$
8. 接受域：否定域的补集。
9. 第一类错误：否定了真理：$P=\left\lbrace\left. refuse\,H_0\right|H_0\,is\,truth\right\rbrace$
10. 第二类错误：接受了假的：$P=\left\lbrace\left. accept\,H_1\right|H_1\,is\,false\right\rbrace$

{/* ---

$\Gamma(x)=\int_0^{+\infty}x^{a-1}e^{-x}dx=\int_0^{+\infty}t^{2a-1}e^{-t^2}dt\implies\Gamma\left(a+1\right)=a\Gamma\left(a\right),\Gamma\left(1\right)=1,\Gamma\left(\dfrac12\right)=\sqrt{\pi},\Gamma(n+1)=n!$

‍ */}
