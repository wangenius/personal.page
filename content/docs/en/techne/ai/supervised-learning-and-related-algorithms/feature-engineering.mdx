---
title: Feature Engineering
sidebar_position: 4
slug: feature-engineering
---

Feature engineering transforms raw data into numerical representations suitable for machine learning.

- **Feature Extraction** – Convert arbitrary inputs (text, images, logs) into vectors via tokenization, embeddings, spectrograms, etc.
- **Preprocessing** – Normalize or standardize features, remove outliers, fix missing values, and address class imbalance.
- **Dimensionality Reduction** – Reduce multivariate data to fewer, decorrelated variables (PCA, autoencoders, feature selection).

## Overfitting

When a model performs well on the training set but poorly on validation data:

1. Collect more diverse data.
2. Reduce the number of features or apply feature selection.
3. Increase regularization strength (`λ`).
4. Use explicit regularizers (L1/L2, dropout, etc.).

## Underfitting

When the model fails to fit even the training data:

1. Add informative features or higher-order terms.
2. Lower regularization strength (`λ`) or adopt a more expressive model.
