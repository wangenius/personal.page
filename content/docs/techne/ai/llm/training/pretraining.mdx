---
title: 预训练 (Pretraining)
---

预训练是 LLM 获得“世界知识”和“语言能力”的关键阶段。在这个阶段，模型在海量未标注的文本数据上进行自我监督学习，消耗了整个训练流程中 99% 以上的算力。

## 核心任务：Next Token Prediction

预训练的核心目标函数非常简单：**预测下一个 Token**。

$$
P(w_t | w_{1}, w_{2}, ..., w_{t-1})
$$

虽然任务看似简单（像是在做完形填空），但为了准确预测下一个词，模型必须学会语法、逻辑、常识、甚至推理能力。例如，要补全 "The capital of France is \_\_\_\_"，模型必须掌握地理知识。

## 数据：LLM 的燃料

预训练数据的质量和数量直接决定了模型的上限。

- **数据来源**: Common Crawl (网页), Wikipedia, GitHub (代码), 书籍, 论文。
- **数据清洗**: 去重（Deduplication）、去毒（Detoxification）、PII 移除（个人隐私保护）、质量过滤。
- **Token 数量**: 现代 LLM 通常在数万亿（Trillions）个 Token 上进行训练。例如 LLaMA 3 在 15T Token 上进行了训练。

## Scaling Laws (缩放定律)

OpenAI 和 DeepMind 的研究表明，LLM 的性能（Loss）与以下三个因素呈幂律关系（Power Law）：

1.  **参数量 (N)**: 模型的大小。
2.  **数据集大小 (D)**: 训练数据的 Token 数量。
3.  **计算量 (C)**: 训练所用的 FLOPs。

**Chinchilla Scaling Law** 指出，为了计算最优，模型参数量和训练数据量应该等比例增加。这意味着很多早期的模型（如 GPT-3）实际上是“训练不足”的，而现代模型（如 LLaMA）倾向于用更多的数据训练相对较小的模型，以便在推理时更高效。

## 预训练的产物：Base Model

预训练结束后的产物被称为 **Base Model（基座模型）**。

- **特点**: 具备强大的续写能力，但不懂指令，不具备对话形式。
- **行为**: 如果你问它“如何做蛋糕？”，它可能会续写“需要的材料有...”，也可能会续写“如何做饼干？”（因为它见过很多类似的问题列表）。
- **下一步**: 为了让模型听懂人话，需要进行 [Alignment (对齐)](./alignment)。
