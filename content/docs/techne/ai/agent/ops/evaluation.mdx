---
title: 智能体评估
---

衡量智能体的不是“输出”，而是“行为质量”

评估智能体从来都不是评估文本质量。传统 NLP 模型的评估方法——BLEU、ROUGE、句子相似度、任务匹配度——对于智能体来说几乎没有意义。一个 Agent 的表现已经不再是单次回答的好坏，而是一个行为序列的完整性：它是否理解了任务、是否在正确的时间采取了正确的行动、是否有效利用了工具、是否能在失败后恢复、是否能保持一致的策略、是否能避免不必要的消耗。

智能体不是一个“生成型模型”，而是一种“行为体”。
而行为体的评估，从来不可能是单点式的，它必须是过程式的。

白皮书在这一章提出一个非常重要的观点：
要评估智能体，就必须把“行为轨迹”当作评估对象，而不是答案。

这意味着我们必须从软件工程、认知科学和系统行为学的角度重新理解“评估”这件事，而不是只看它在终端吐出的那段文本。

---

## 评估的本质是衡量“任务完成质量”

一个 Agent 是否“聪明”，不是看它说得好不好，而是看它是否能在复杂情境中完成任务。任务不是一句话，而是一段旅程。旅程包括误解、探索、拆解、规划、行动、修复、优化、校准、终止。评估必须覆盖这些阶段，而不仅仅是最终产物。

这意味着，一个智能体的输出即使看起来“不错”，它仍然可能是失败的，因为：

它可能走了完全错误的路径；
它可能调用了错误的工具；
它可能绕了一圈才回到正确答案；
它可能漏掉关键步骤；
它可能在错误状态下继续运行；
它可能给了正确结果但违反了策略；
它可能成本极其高、操作极其慢。

换句话说，智能体的表现必须像评估一个“在职员工”一样来衡量，而不能像评估一篇作文一样来看待。

---

## 轨迹（trace）才是真正的评估对象

真正的评估目标不是模型的文本，而是：

智能体如何思考；
智能体在每一步做了什么；
它对上下文的理解是否稳定；
它调用工具的理由是否合理；
它的计划是否自洽；
它是否能在失败后调整策略；
它是否会陷入循环或荒诞推理；
它是否能收敛到正确路径；
它是否能在合适的节点终止任务。

因此，一个智能体的评估必须基于“轨迹回放”——一个可重现、可观察、可逐步反推的行为记录。
评估不是一张分数，而是一种“行为意义分析”。

就像你不会只看一个员工的结果，而会看他是如何抵达结果的。

---

## 评估必须通过“智能体评估智能体”的方式来完成

随着智能体行为变得越来越复杂，人类已经不再可能手工评估所有任务的质量。在真实系统中，一天甚至一小时的Agent调用就可能超过上万次，而其中每一次都包含数十个推理循环。没有任何人工评审团队能够处理这样的数据量。

因此白皮书提出一种现在看来必然的思路：
智能体需要由智能体来评估。

这并不是“自动打分”，而是一种“模型驱动的行为审查机制”。
评估智能体会读取另一位智能体的所有轨迹：观察它的每一步行动，判断其合理性，解释错误来源，总结任务达成程度，并提供结构化反馈。

这种“评估智能体”本身也是智能体体系中的一部分，它承担的是一种“审计角色”。正如公司中需要审计，智能体系统中也需要审计，而审计必须是智能化的、规模化的、持久化的。

---

## 评估的关键不是对错，而是“偏差模式”

人类的错误往往是重复的，而智能体的错误也具备“模式性”。
通过系统层面的持续评估，可以识别：

它在哪类任务中容易误解需求；
它在哪类信息中容易丢失结构；
它遇到哪种工具失败会产生极端行为；
它的计划在哪些场景变得松散或过度冗长；
它在哪些地方变得自信过度；
它在哪些地方表现得过度谨慎。

这些错误不是 bug，而是心智结构的偏差。
偏差一旦被识别，就可以通过修正 persona、强化 domain knowledge、优化 context engineering 或调整 memory 写入策略来解决。

评估不是终点，而是“反馈系统的一部分”。
智能体不是通过一次性训练变得更好，而是通过评估驱动的一次次小幅调整，最终演化为更稳定的系统智能。

---

## 评估最终的意义：打造可持续演化的智能体体系

无论模型如何更新、工具如何扩展、模态如何叠加，智能体的行为都必须保持可预期、可治理、可解释、可持续。唯一的途径，就是一个持续运行的评估体系——不只是测试，而是持续分析智能体的行为生态。

换句话说，评估不是为了衡量模型的好坏，而是为了维持系统的健康。
它是一种免疫系统，是智能体的元治理机制，是未来所有 Agent 系统能够形成“可控智能”的根本条件。

没有评估，再强的模型也可能在关键场景中失控。
有了评估，一个看似普通的模型也能在系统中逐渐被雕刻成可靠的智能体。

这就是评估的终极价值：
把智能体从一次性推理，变成一个能够被反思、被矫正、被塑造的长期存在。
