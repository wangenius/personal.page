---
title: Agent 互操作性
---

Agent、Human 与 Agent 之间的“语言与协议”

在前面的章节里，我们把智能体视为一个能够推理、执行、协作的独立个体。然而，当智能体真正走向生产环境，它并不会独自生存。它需要与人沟通，需要与其他智能体协作，也需要与外部系统对接。一个孤立的 Agent 无法发挥价值，正如一个离群的人类个体无法构建社会结构。真正的智能系统必然是互操作的，而互操作性所依赖的不是模型，而是语言、协议与结构化的沟通方式。

互操作性的问题听起来像是“通信层面”的技术细节，但它的本质更接近社会学：当两个 Agent 交流时，它们必须共享某种对世界的结构性理解，必须能够解释彼此的意图、任务、状态与限制。更困难的是，它们都使用自然语言，而自然语言具有歧义、冗余、隐含语义和上下文依赖。一个没有协议的多 Agent 系统会像一群人类在黑暗房间里各说各话，信息会迅速溃散、误解会不断累积，最终导致系统行为失控。

因此，智能体之间的沟通必须通过一种“结构化的自然语言”。这听起来矛盾，但正是白皮书提出的重要观点：智能体不需要放弃自然语言的灵活性，但它们必须在自然语言之下隐藏一层稳定的结构，让每次交流都具备可验证性与可解析性。这种结构就是所谓的 “Agent Cards”。

---

## **Agent Cards：为智能体定义“可被理解的身份”**

Agent Card 的初衷，是为每个智能体建立一种“可被读取的自我描述”。一个 Agent Card 包含了智能体的能力、角色、输入输出规则、工具权限、风格偏好与任务边界。这种描述不仅对人类可读，更关键的是对其他智能体可读。换句话说，一个 Agent Card 就像一个“智能体 API 文档”，它让协作不再依赖随机的自然语言推断，而由一种被共享的结构标准来支撑。

当一个智能体在委派任务时，它并不是简单地把自己的 Prompt 传给另一个智能体，而是读取对方的 Agent Card，理解对方适合承担什么任务、接受怎样的输入、期待怎样的输出、具有什么工具、遵循什么风格，并根据这些条件构建“对方能理解的请求”。这相当于一种协议层上的协商，让多智能体系统从混乱走向秩序。参与协作的每个 Agent 都有自己的“自我结构”，这让协作不再依赖模型的猜测，而依赖编排层的稳定规则。

在工程意义上，Agent Card 是一种元数据，一种塑造智能体行为的“内在文档”。但在系统意义上，它是一种“社会身份”。它决定了一个智能体在网络中的地位、能力范围与责任。它让智能体之间的沟通像 API 调用，而不是随意闲聊。

---

## **自然语言作为协议，而不是噪声通道**

人类与 Agent 的沟通依然是自然语言，但白皮书指出，随着智能体协作的深化，自然语言不应被视为一种“随意表达方式”，而应该被视为一种“协议载体”。自然语言具备高度表达力，但模型很容易因为上下文干扰而误解其结构。为了避免这种情况，智能体在沟通中会逐渐形成其自己的“准协议语言”：表面上看是人类语言，内部却维持着结构化的纹理。

例如，一个智能体向另一个智能体提出请求时，不只是给出任务说明，而是通过一种固定的段落模式、标注方式、或隐含的字段形式来传递语义。这些结构可以由 orchestrator 自动添加，也可以在 Agent Card 中指定。一旦这种结构形成，智能体之间的沟通就进入了一个新的层级：既保留自然语言的表达能力，又具有机器协议的稳定性。

这种结构化的自然语言会逐渐成为一种新型“Agent 语域（agentic register）”。就像科研论文有自己的语言规范、法律文件有自己的语义框架、工程代码有自己的风格指南，智能体也会形成一种“介于人类语言与数据结构之间”的沟通方式。这种方式的出现，不是因为我们设计它，而是因为复杂系统的协作本身需要它。

---

## **面对歧义、噪声与不完整信息：智能体如何互相校准？**

智能体之间的互操作性面临另一个本质挑战：它们看到的世界从不完全一致。每个 Agent 的上下文、记忆、工具、策略都可能不同，它们对同一个任务的理解不可避免地产生偏差。这时，多 Agent 系统必须具备一种“互相校准”的机制，就像人类在协作时会通过会话来对齐彼此的理解。

这种校准不是通过一次性的大声明来完成，而是通过多轮对话逐步达成。一个智能体在收到另一个智能体的任务请求后，可能会提出澄清问题，要求更多信息，或拒绝执行某些越界的任务。白皮书强调，这种“来回确认”的过程并不是低效，而恰恰是系统保持安全性、可靠性与透明度的关键。一个智能体如果不提问、不校准、直接执行，它往往就是不可靠的。

随着系统成熟，这种校准机制会越来越结构化。例如，一个 Agent 在委派任务之前会自动生成预期结构、成功标准与错误条件；接收任务的 Agent 会在启动执行前明确“我接受任务”或“我无法接受，你需要换别人”。这种机制形成后，智能体之间就不再是松散沟通，而变成了真正的“合同协议式协作”。

---

## **A ↔ H ↔ A：未来软件的接口不是函数，而是对话**

互操作性不仅发生在 Agent 与 Agent 之间，也发生在人类与 Agent 之间。人类提供任务，Agent 执行；执行过程中 Agent 会要求人类确认；人类修改需求后 Agent 会更新计划；多个 Agent 协作过程中也会向人类报告、请示或请求决策。过去软件系统的接口是按钮、表单和 API；未来系统的接口则是对话、任务图、角色描述与行为协议。

对人类来说，智能体成为了一种新的“对话式 API”。你不再需要编写流程，而是通过交流让系统理解需求。对智能体来说，人类的存在既是监督者，也是任务的补全者和风险的守门人。智能体会通过协议式语言向人类传递“我现在在做什么”“我需要你确认什么”“我遇到了什么异常”“我需要更多信息”，而人类通过回答与调整，继续塑造智能体的行为轨迹。

这种三方互操作性形成了一种新的操作系统界面——一个围绕意图、任务、协作的界面，而不是围绕按钮和工具栏的界面。

---

## **互操作性的终点：Agent 社会与 Agent 协议层**

当所有智能体都能够理解彼此的能力、边界与输出形式，它们自然会构成一种“Agent 社会”。这种社会的基础不是情感或文化，而是协议与结构。每个 Agent 有它的角色，每个 Agent 有它的责任，每个 Agent 有它的身份卡、语言规范与协作方式。

未来的智能系统不会是一个巨大的模型，而是一层“Agent 协议层”，其地位类似于过去互联网协议层——为无数独立节点提供统一的语言、规则和协作方式。模型只是节点的智能引擎，而协议层才是形成网络智能的基础设施。

这就是互操作性的最终意义：不是让智能体之间“能讲话”，而是让智能体之间“能以一种可靠、可控、可演化的方式协作”。系统的智能不再源自单一模型的能力，而源自整个网络中智能体之间的结构化沟通。真正的智能社会，将从这里开始。

---

如果你愿意，我可以继续写 **Part 11：Agent Modalities（多模态、代码执行、浏览器、工具生态）**，同样会以自然段落的方式展开。
